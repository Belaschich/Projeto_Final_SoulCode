{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjetoFinal (Spark Oficial) 19.11.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SSkAJhCPmuiL",
        "pej0FLIDnC9f",
        "dvEInwyOo3lm",
        "3H4uKKRTwWUc",
        "mIPpMPcFweEt",
        "Fo-HvSG1Z6-k",
        "PfBk2hK9wbpB"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Belaschich/Projeto_Final_SoulCode/blob/main/ProjetoFinal_(Spark_Oficial)_19_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSkAJhCPmuiL"
      },
      "source": [
        "# IMPORT BIBLIOTECAS E ACESSO GCP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LwlkjPVJ1mT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ade19c9-8b66-4ea1-934a-0a911b856d3e"
      },
      "source": [
        "pip install gcsfs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gcsfs\n",
            "  Downloading gcsfs-2021.11.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gcsfs) (2.23.0)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.7/dist-packages (from gcsfs) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.7/dist-packages (from gcsfs) (0.4.6)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (from gcsfs) (1.18.1)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.7/dist-packages (from gcsfs) (4.4.2)\n",
            "Collecting fsspec==2021.11.1\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting aiohttp<4\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 46.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4->gcsfs) (21.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4->gcsfs) (2.0.8)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4->gcsfs) (3.10.0.2)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 47.8 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 67.3 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 62.4 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (57.4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.8)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp<4->gcsfs) (2.10)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (2021.10.8)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->gcsfs) (1.0.3)\n",
            "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->gcsfs) (0.4.1)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->gcsfs) (1.26.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->gcsfs) (3.17.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->gcsfs) (21.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->gcsfs) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->gcsfs) (1.53.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->gcsfs) (3.0.6)\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, gcsfs\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 frozenlist-1.2.0 fsspec-2021.11.1 gcsfs-2021.11.1 multidict-5.2.0 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43ufK9DYKPVx"
      },
      "source": [
        "#BIBLIOTECA PARA CHAVE DE ACESSO GCP\n",
        "\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn-PFsrUK_Ha"
      },
      "source": [
        "#IMPORT PANDAS E STORAGE\n",
        "\n",
        "import pandas as pd\n",
        "from google.cloud import storage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lr2x2GbKRTz"
      },
      "source": [
        "#IMPORTA BASE DE ACESSO GCP\n",
        "\n",
        "service_account_key = r\"/content/chaveprogrupo10-332518-4db3212adcd1.json\"\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = service_account_key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6Pbcy_kvwaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0fd1a8f-0847-4ef4-ab59-5b03c07ec738"
      },
      "source": [
        "pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 38 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.2\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 54.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=ac26d128c88be52272acdf34b0ed965a29b2123e9db2a13300bfaa3f624b5905\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RxYrSHTv4Hc"
      },
      "source": [
        "#IMPORT BIBLIOTECAS SPARK\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.types import StructField, StructType, StringType, IntegerType, DoubleType, DateType\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRcfmIKLv4xx"
      },
      "source": [
        "#PREPARAÇÃO SPARK SESSION\n",
        "\n",
        "spark = (SparkSession.builder\n",
        "        .master(\"local\")\n",
        "        .appName(\"novo-dataframes\")\n",
        "        .config(\"spark.ui.port\", \"4050\")\n",
        "        .getOrCreate())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srkbbUn6b_MP"
      },
      "source": [
        "#IMPORTAÇÃO BASE \"AMERICA DO NORTE\" SALVO NO GCP\n",
        "\n",
        "df1 = pd.read_csv('gs://bucket-projeto-g10/saida_tratado/nivel_pandera/Base_ConsumoNA (2.0).csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pej0FLIDnC9f"
      },
      "source": [
        "# ALTERAÇÕES PANDAS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-Y3ugAIdlqW"
      },
      "source": [
        "#RENOMEIA A COLUNA \"ESTADO\" PARA \"UF\"\n",
        "\n",
        "df1 = df1.rename({'Estado': 'UF'}, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz-YU_4sdnfj"
      },
      "source": [
        "#CRIA UMA COLUNA \"CLIMA\" COM VALORES NaN\n",
        "\n",
        "df1['Clima'] = 'NaN'\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nArvRCbdoas"
      },
      "source": [
        "#INSERE DADOS NA COLUNA \"CLIMA\" COM CONDIÇÕES\n",
        "\n",
        "for index, row in df1.iterrows():\n",
        "    if row['UF'] == 'Alaska':\n",
        "        df1.loc[index,'Clima'] =  str('Polar')\n",
        "   \n",
        "        df1.loc[index,'Clima'] =  str('Seco')\n",
        "    elif row['UF'] == 'Connecticut' or row['UF'] == 'Massachusetts'or row['UF'] == 'Minnesota' or row['UF'] == 'Dakota do Norte':\n",
        "        df1.loc[index,'Clima'] =  str('Continental' elif row['UF'] == 'Colorado':)\n",
        "    elif row['UF'] == 'Delaware' or row['UF'] == 'Florida' or row['UF'] == 'Illinois' or row['UF'] == 'Kentucky' or row['UF'] ==  'Missouri'or row['UF'] ==  'Tennessee' or row['UF'] ==  'Texas' or row['UF'] ==  'Iowa':\n",
        "        df1.loc[index,'Clima'] =  str('Subtropical') \n",
        "\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WaME988drtH"
      },
      "source": [
        "#VALIDAÇÃO DA COLUNA \"CLIMA\"\n",
        "\n",
        "pd.unique(df1['Clima'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsIebeUwdskw"
      },
      "source": [
        "#VERIFICA DADOS UNICOS DA COLUNA \"UF\"\n",
        "\n",
        "pd.unique(df1['UF'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZDkrarPdtql"
      },
      "source": [
        "#CRIA UMA COLUNA \"ESTAÇÃO DO ANO\" COM VALORES NaN\n",
        "\n",
        "df1['EstacaoDoAno'] = 'NaN'\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23c6iJDSdwQT"
      },
      "source": [
        "#INSERE DADOS NA COLUNA \"ESTAÇÃO DO ANO\" COM CONDIÇÕES\n",
        "\n",
        "for index, row in df1.iterrows():\n",
        "    if row['Mes'] == 6 or row['Mes'] == 7 or row['Mes'] == 8:\n",
        "        df1.loc[index,'EstacaoDoAno'] =  str('Verão')\n",
        "    elif row['Mes'] == 12 or row['Mes'] == 1 or row['Mes'] == 2:\n",
        "        df1.loc[index,'EstacaoDoAno'] =  str('Inverno')\n",
        "    elif row['Mes'] == 3 or row['Mes'] == 4 or row['Mes'] == 5:\n",
        "        df1.loc[index,'EstacaoDoAno'] =  str('Primavera') \n",
        "    elif row['Mes'] == 9 or row['Mes'] == 10 or row['Mes'] == 11:\n",
        "        df1.loc[index,'EstacaoDoAno'] =  str('Outono') \n",
        "\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npOJc8b3d0Sx"
      },
      "source": [
        "#RENOMEIA OS DADOS DA COLUNA \"UF\"\n",
        "\n",
        "df1['UF'].replace('Alaska', 'AK', inplace=True)\n",
        "df1['UF'].replace('Colorado', 'CO', inplace=True)\n",
        "df1['UF'].replace('Connecticut', 'CT', inplace=True)\n",
        "df1['UF'].replace('Delaware', 'DE', inplace=True)\n",
        "df1['UF'].replace('Florida', 'FL', inplace=True)\n",
        "df1['UF'].replace('Illinois', 'IL', inplace=True)\n",
        "df1['UF'].replace('Kentucky', 'KY', inplace=True)\n",
        "df1['UF'].replace('Massachusetts', 'MA', inplace=True)\n",
        "df1['UF'].replace('Minnesota', 'MN', inplace=True)\n",
        "df1['UF'].replace('Missouri', 'MO', inplace=True)\n",
        "df1['UF'].replace('Dakota do Norte', 'ND', inplace=True)\n",
        "df1['UF'].replace('Tennessee', 'TN', inplace=True)\n",
        "df1['UF'].replace('Texas', 'TX', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvEInwyOo3lm"
      },
      "source": [
        "# NÍVEL SPARK (TRATATIVA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY_2jUr1w3h9"
      },
      "source": [
        "#CRIAÇÃO DO \"STRUCTURED TYPE\" PARA OS DADOS DO DATAFRAME \"AMÉRICA DO NORTE\"\n",
        "\n",
        "customSchema = StructType([\n",
        "    StructField(\"Ano\", IntegerType(), True),\n",
        "    StructField(\"Mes\", IntegerType(), True),\n",
        "    StructField(\"MesRef\", StringType(), True),\n",
        "    StructField(\"UF\", StringType(), True),\n",
        "    StructField(\"Categoria\", StringType(), True),\n",
        "    StructField(\"Galoes\", IntegerType(), True),\n",
        "    StructField(\"Etanol\", IntegerType(), True),\n",
        "    StructField(\"Populacao\", IntegerType(), True),\n",
        "    StructField(\"EtanolPerCapita\", DoubleType(), True),\n",
        "    StructField(\"Clima\", StringType(), True),\n",
        "    StructField(\"EstacaoDoAno\", StringType(), True),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8BPtBy8v_Vd"
      },
      "source": [
        "#CRIA UM DATAFRAME SPARK, COM BASE NOS DADOS DO DF \"AN\" CRIADO EM PANDAS\n",
        "\n",
        "df1_spark = spark.createDataFrame(df1, schema=customSchema) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOZtNm7B2plB"
      },
      "source": [
        "#EXIBE OS DADOS DO DF CONVERTIDO\n",
        "\n",
        "df1_spark.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8InVPORNJf8"
      },
      "source": [
        "df1_spark.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNvQJ7d9eE6j"
      },
      "source": [
        "#CRIA UM RANK SOBRE A QUANTIDADE DE ETANOL VENDIDO\n",
        "\n",
        "w0 = Window.orderBy(F.col(\"Etanol\"))\n",
        "df2 = df1_spark.withColumn(\"rank\", F.row_number().over(w0))\n",
        "df2.select(F.col(\"Ano\"), F.col(\"Mes\"), F.col(\"UF\"), F.col(\"Etanol\") , F.col('Populacao'),\n",
        " F.col(\"rank\")).show(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvhL13CVeGnR"
      },
      "source": [
        "#CRIA UMA COLUNA DE GALÕES PER CAPITA (GALÕES / POPULAÇÃO)\n",
        "\n",
        "df2 = df1_spark.withColumn(\"GaloesPerCapita\", F.col(\"Galoes\") / F.col(\"Populacao\"))\n",
        "df2.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H4uKKRTwWUc"
      },
      "source": [
        "# INSIGHTS SPARK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHrXHaK8pwUM"
      },
      "source": [
        "#CRIA UM AGRUPAMENTO DE GALOES PER CAPITA POR \"UF\"\n",
        "\n",
        "group1 = (df2.groupBy(F.col(\"UF\")).agg(\n",
        "            F.sum(\"GaloesPerCapita\").alias(\"Soma_GaloesPC\"),\n",
        "            F.avg(\"GaloesPerCapita\").alias(\"Med_GaloesPC\")\n",
        "            )\n",
        ").orderBy(F.sum('GaloesPerCapita').desc())\n",
        "\n",
        "group1.show()\n",
        "\n",
        "#INSIGHTS:\n",
        "#DAKOTA DO NORTE APRESENTOU MAIOR CONSUMO (MÉDIA DE 1 GALÃO PER CAPITA)\n",
        "#KENTUCKY APRESENTOU MENOR CONSUMO (0.7 GALÕES PER CAPITA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7abGrFfqWio"
      },
      "source": [
        "#CRIA UM AGRUPAMENTO DE GALOES PER CAPITA POR \"MESREF\" E \"UF\"\n",
        "\n",
        "group2 = (df2.groupBy(F.col(\"MesRef\"), F.col(\"UF\")).agg(\n",
        "            F.sum(\"GaloesPerCapita\").alias(\"Soma_GaloesPC\"),\n",
        "            F.avg(\"GaloesPerCapita\").alias(\"Med_GaloesPC\")\n",
        "            )\n",
        ").orderBy(F.col('MesRef').desc())\n",
        "\n",
        "group2.show(1000)\n",
        "\n",
        "#INSIGHT:\n",
        "#PODE SER USADO PARA CRIAR UM ESTUDO DE PERÍODO COM FILTROS DE ANO E UF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_h6Oi06sEbL"
      },
      "source": [
        "#CRIA UM RANK SOBRE A QUANTIDADE DE \"GALÕES PER CAPITA\" POR PERÍODO E \"UF\"\n",
        "\n",
        "w1 = Window.orderBy(F.col(\"GaloesPerCapita\").desc())\n",
        "\n",
        "df2_rank = df2.withColumn(\"rank\", F.row_number().over(w1))\n",
        "df2_rank.select(F.col(\"Ano\"), F.col(\"Mes\"), F.col(\"UF\"), F.col(\"GaloesPerCapita\"), \n",
        " F.col(\"rank\")).show(1000)\n",
        "\n",
        "#GERA UM INSIGHT RÁPIDO SOBRE MAIOR CONSUMO POR PERÍODO E UF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XEuLettuwbs"
      },
      "source": [
        "#CRIA UM RANK SOBRE A QUANTIDADE DE \"ETANOL PER CAPITA\" VENDIDO\n",
        "\n",
        "w1 = Window.orderBy(F.col(\"EtanolPerCapita\").desc())\n",
        "df2_rank = df2.withColumn(\"rank\", F.row_number().over(w0))\n",
        "df2_rank.select(F.col(\"Ano\"), F.col(\"Mes\"), F.col(\"UF\"), F.col(\"EtanolPerCapita\"), \n",
        " F.col(\"rank\")).show(1000)\n",
        "\n",
        "\n",
        "#GERA UM INSIGHT RÁPIDO SOBRE MAIOR CONSUMO POR PERÍODO E UF NA VISÃO ETANOL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z25Vk2zwvFce"
      },
      "source": [
        "#CRIA UM RANK SOBRE A QUANTIDADE DE \"GALÕES PER CAPITA\" VENDIDO POR TIPO DE CLIMA\n",
        "\n",
        "(df2.groupBy(F.col(\"Clima\")).agg(\n",
        "            F.sum(\"GaloesPerCapita\").alias(\"Sum_GaloesPerCapita\"),\n",
        "            ).show()\n",
        ")\n",
        "\n",
        "#INSIGHTS:\n",
        "#MAIOR CONSUMO NAS REGIOES SUBTROPICAIS\n",
        "#MENOR CONSUMO NAS REGIOES POLAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIPpMPcFweEt"
      },
      "source": [
        "# SPARK SQL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaMaV6oqyTez"
      },
      "source": [
        "#CRIANDO UMA TABELA A PARTIR DO PYSPARK \n",
        "\n",
        "df2.createOrReplaceTempView(\"Tab_AN\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31KLOpOUxmKl"
      },
      "source": [
        "#EXIBE EA TABELA CRIADA \"Tab_AN\"\n",
        "\n",
        "spark.sql(\"SELECT * FROM Tab_AN\").show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmpqJsSwzHoq"
      },
      "source": [
        "#AJUSTANDO O MESREF E CRIANDO UMA NOVA TABELA MAIS FUNCIONAL \"Tab_AN_Novo\"\n",
        "\n",
        "spark.sql(\n",
        "''' \n",
        "SELECT \n",
        "CASE WHEN CHARACTER_LENGTH(MesRef) == 5 THEN CONCAT('0', MesRef)\n",
        "ELSE MesRef\n",
        "END AS MesRefNovo,\n",
        "UF,\n",
        "Categoria,\n",
        "Galoes,\n",
        "Etanol,\n",
        "Populacao,\n",
        "EtanolPerCapita,\n",
        "Clima,\n",
        "EstacaoDoAno,\n",
        "GaloesPerCapita\n",
        "FROM Tab_AN \n",
        "'''\n",
        "          ).createOrReplaceTempView(\"Tab_AN_Novo\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buFDH6gA26nz"
      },
      "source": [
        "#CRIANDO UM INSIGHT DE CONSUMO POR POPULAÇÃO E ESTADO\n",
        "\n",
        "spark.sql(\n",
        "''' \n",
        "SELECT \n",
        "UF,\n",
        "ROUND(SUM(Populacao),2) AS SUM_POPULACAO,\n",
        "ROUND(SUM(EtanolPerCapita),2) AS SUM_ETANOLPC,\n",
        "ROUND(SUM(GaloesPerCapita),2) AS SUM_GALOESPC,\n",
        "ROUND(AVG(GaloesPerCapita),2) AS MED_GALOESPC\n",
        "FROM Tab_AN_Novo\n",
        "GROUP BY UF\n",
        "ORDER BY UF\n",
        "'''\n",
        "          ).show(1000000)\n",
        "\n",
        "#INSIGHTS:\n",
        "#MAIOR CONSUMO: DAKOTA DO NORTE (GALÕES PC) E DELAWARE (ETANOL PC)\n",
        "#MENOR CONSUMO: KENTUCKY (GALÕES E ETANOL PC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao-9kROm4MOM"
      },
      "source": [
        "# CRIANDO UM INSIGHT DE SOMA  DE GALÕES POR CATEGORIA E ESTADO\n",
        "spark.sql(\n",
        "''' \n",
        "SELECT \n",
        "UF,\n",
        "CATEGORIA,\n",
        "ROUND(SUM(GaloesPerCapita),2) AS SUM_GALOESPC\n",
        "FROM Tab_AN_Novo\n",
        "GROUP BY UF, CATEGORIA\n",
        "ORDER BY UF, CATEGORIA\n",
        "'''\n",
        "          ).show(1000000)\n",
        "\n",
        "#INSIGHTS:\n",
        "#MAIOR CONSUMIDOR DE CERVEJA: DAKOTA DO NORTE\n",
        "#MAIOR CONSUMIDOR DE DESTILADOS: DELAWARE\n",
        "#MAIOR CONSUMIDOR DE VINHOS: DELAWARE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2X_-mtG5S3y"
      },
      "source": [
        "#CRIANDO INSIGHT DE CONSUMO POR ANO E SEMESTRE\n",
        "\n",
        "spark.sql(\n",
        "''' \n",
        "SELECT \n",
        "RIGHT(MesRefNovo, 4) AS ANO,\n",
        "CASE WHEN LEFT(MesRefNovo, 2) Between 01 and 06 THEN 'Primeiro Semestre'\n",
        "ELSE 'Segundo Semestre'\n",
        "END AS Semestre,\n",
        "ROUND(SUM(EtanolPerCapita),2) AS SUM_ETANOLPC,\n",
        "ROUND(SUM(GaloesPerCapita),2) AS SUM_GALOESPC,\n",
        "ROUND(AVG(GaloesPerCapita),2) AS MED_GALOESPC\n",
        "FROM Tab_AN_Novo \n",
        "GROUP BY ANO, Semestre \n",
        "ORDER BY ANO, Semestre\n",
        "'''\n",
        "          ).show(10000)\n",
        "\n",
        "#INSIGHTS:\n",
        "#MAIOR CONSUMO NO SEGUNDO SEMESTRE DE 2020\n",
        "#MENOR CONSUMO NO PRIMEIRO SEMESTRE DE 2019 E 2020 \n",
        "#OBS: DESCONSIDERAMOS 2021 POR TER APENAS 2 MESES DE COMPARATIVO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEhqGWzU9LKV"
      },
      "source": [
        "#CRIANDO INSIGHT DE CONSUMO POR ESTAÇÃO DO ANO\n",
        "spark.sql(\n",
        "''' \n",
        "SELECT \n",
        "RIGHT(MesRefNovo, 4) AS ANO,\n",
        "EstacaoDoAno,\n",
        "ROUND(SUM(EtanolPerCapita),2) AS SUM_ETANOLPC,\n",
        "ROUND(SUM(GaloesPerCapita),2) AS SUM_GALOESPC,\n",
        "ROUND(AVG(GaloesPerCapita),2) AS MED_GALOESPC\n",
        "FROM Tab_AN_Novo \n",
        "GROUP BY ANO, EstacaoDoAno \n",
        "ORDER BY ANO, EstacaoDoAno\n",
        "'''\n",
        "          ).show(10000)\n",
        "\n",
        "#INSIGHTS:\n",
        "#MAIOR CONSUMO GERAL NO VERÃO \n",
        "#MENOR CONSUMO GERAL NO INVERNO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNIGTExZ-a5E"
      },
      "source": [
        "#CRIANDO INSIGHT DE CONSUMO POR PRODUTO EM CADA ÉPOCA DO ANO\n",
        "spark.sql(\n",
        "''' \n",
        "SELECT \n",
        "EstacaoDoAno,\n",
        "Categoria,\n",
        "ROUND(SUM(GaloesPerCapita),2) AS SUM_GALOESPC\n",
        "FROM Tab_AN_Novo\n",
        "GROUP BY EstacaoDoAno, Categoria\n",
        "ORDER BY EstacaoDoAno, Categoria\n",
        "'''\n",
        "          ).show(10000)\n",
        "\n",
        "#INSIGHTS:\n",
        "# MAIOR CONSUMO DE CERVEJA DURANTE VERÃO\n",
        "# MAIOR CONSUMO DE DESTILADO DURANTE O INVERNO\n",
        "# MAIOR CONSUMO DE VINHO DURANTE O INVERNO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo-HvSG1Z6-k"
      },
      "source": [
        "# PLOTAGEM PANDAS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgdNq7fTZ_N6"
      },
      "source": [
        "#CONVERTE O DF DE SPARK PARA PANDAS QUE SERÁ USADO PARA AS PLOTAGENS\n",
        "\n",
        "df2_plot = df2.toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "858kohHChwJF"
      },
      "source": [
        "g2 = df2_plot.groupby(['Ano', 'Mes'])['GaloesPerCapita'].agg('mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN4ZdVAKh4Rx"
      },
      "source": [
        "g2.plot(x=\"Ano\", y=[\"GaloesPerCapita\"], kind=\"bar\",figsize=(20,8))\n",
        "\n",
        "\n",
        "#INSIGHTS:\n",
        "#MAIOR CONSUMO GERAL ENTRE MAIO E AGOSTO\n",
        "#MENOR CONSUMO GERAL ENTRE JANEIRO E FEVEREIRO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SounfthBgOLb"
      },
      "source": [
        "g3 = df2_plot.groupby(['Ano', 'Mes'])['EtanolPerCapita'].agg('mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkLHiM9mgwBp"
      },
      "source": [
        "g3.plot(x=\"Ano\", y=[\"EtanolPerCapita\"], kind=\"bar\",figsize=(20,8))\n",
        "\n",
        "#INSIGHTS:\n",
        "#COMPORTAMENTO SEMELHANTE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO5RwOU2jmZj"
      },
      "source": [
        "filtro_ano = df2_plot.Ano == 2020\n",
        "\n",
        "df3_plot = df2_plot.loc[filtro_ano]\n",
        "\n",
        "g3 = df3_plot.groupby(['UF'])['EtanolPerCapita'].agg('mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kheRS0f1knuC"
      },
      "source": [
        "g3.plot(x=\"UF\", y=[\"EtanolPerCapita\"], kind=\"line\",figsize=(20,8))\n",
        "\n",
        "#INSIGHTS:\n",
        "#EM 2020 DELAWARE FOI O MAIOR CONSUMIDOR\n",
        "#KENTUCKY FOI O MENOR CONSUMIDOR NESTE MESMO ANO\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTj4FkQ6k2Yd"
      },
      "source": [
        "filtro_ano = df2_plot.Ano == 2020\n",
        "\n",
        "df4_plot = df2_plot.loc[filtro_ano]\n",
        "\n",
        "g4 = df4_plot.groupby(['UF'])['GaloesPerCapita'].agg('mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw96RLYKlAjX"
      },
      "source": [
        "g4.plot(x=\"UF\", y=[\"GaloesPerCapita\"], kind=\"barh\",figsize=(20,8))\n",
        "\n",
        "#INSIGHTS:\n",
        "#EM 2020 TIVEMOS KENTUCKY E CONNECTICUT FORAM OS MENORES CONSUMIDORES\n",
        "#COM VALORES PRÓXIMOS ENTRE SI"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfBk2hK9wbpB"
      },
      "source": [
        "# EXPORTAÇÃO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh56V0Asj7Aj"
      },
      "source": [
        "#df2.toPandas().to_csv('gs://bucket-projeto-g10/saida_tratado/nivel_spark/Base_ConsumoNA (3.0).csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bztTqNHORA2"
      },
      "source": [
        "#df2.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}